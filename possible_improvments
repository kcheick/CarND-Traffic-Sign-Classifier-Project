// improvements
- different networks arch 
- change the dimensions of the layers 
- regularization feature to prevent over fitting
   dropout
   l2 regularization
- tune hyper parameters
- improve pre processing
	- normalization 
	- zero mean MEAN
- augment the training data 
	- rotating 
	- change colors



change,accuracy,comment
no change, 0.89

no changes
[0.6507936510099035, 0.7759637186857038, 0.79297052167710802, 0.82154195043775768, 0.83605442187683388, 0.85668934275503872, 0.84648526114941725, 0.85306122454385913, 0.87233560098812424, 0.85782312963014284]
dropout 0.5
[0.41791383218603068, 0.62403628155758051, 0.68684807253532665, 0.74603174613987233, 0.77732426336292781, 0.78004535166314404, 0.81632653093662388, 0.83151927413313298, 0.8442176873451458, 0.84965986421589412]
normalization
[0.63922902505143697, 0.766666666774793, 0.82970521544653275, 0.85532879845625687, 0.86666666699104566, 0.87981859388805572, 0.87823129254403842, 0.87868480755358325, 0.89070294762955227, 0.89909297081888939]
regularization
[0.63492063502876128, 0.75850340146867057, 0.80000000008109473, 0.80453514723010078, 0.7981859413944945, 0.79115646280128671, 0.7734693876469757, 0.74376417195715872, 0.73514739258759687, 0.75895691574836266]
greyscale
[0.66258503425688975, 0.79501133819285974, 0.82108843569852863, 0.83922902529472121, 0.83968253933112913, 0.8517006800558562, 0.8526077095072826, 0.8582766442882771, 0.86122448960669729, 0.87210884386179399]
normalization + dropout + greyscale
[0.60634920615998522, 0.78707482998603595, 0.80068027186555923, 0.84761904761904761, 0.86530612244897964, 0.87006802721088439, 0.88820861678004537, 0.87868480725623588, 0.89092970548573536, 0.90045351473922908, 0.90068027237915937, 0.90362811791383224, 0.90657596398913676, 0.91179138321995468, 0.91859410457870583, 0.91269841296872856, 0.92199546485260775, 0.91541950140410266, 0.91609977324263037, 0.91405895718641561, 0.90975056716373992, 0.90793650820682381, 0.91972789115646258, 0.90929705215419498, 0.92018140616600741]


no changes
0.85782312963014284
dropout 0.5 : tf.nn.dropout(conv1, 0.5)
0.84965986421589412
normalization: tf.nn.l2_normalize(x, dim=1), tf.nn.l2_normalize(x, dim=2)
0.89909297081888939
l2 regularization : loss_operation = tf.reduce_mean(loss_operation + conv1_b * tf.nn.l2_loss(conv1_W))
0.75895691574836266
greyscale : tf.image.rgb_to_grayscale(x)
0.87210884386179399



layer1 

data,
conv,
relu,
dropout
max_pool

layer2 

layer1_output,
conv,
relu,
max_pool

layer3

concat(layer1_output, layer2_output),
Fully_connected